\chapter{Results}

In this section, the results on the benchmark dataset are briefly presented followed by the results on the financial data.
The results from the movement of indices are displayed in Section \ref{sec:res_dir}. Finally, the results from the prediction of the ARMA-forecasts are presented in Section \ref{sec:res_arma}. Again, this classification problem aims to predict if the ARMA-forecast is higher or lower than the actual outcome. 

The performance is presented as accuracy and macro average F1-score in the test set for all models. 

\section{Benchmark Evaluation}

The results on the IMDb dataset for benchmarking are presented in Table~\ref{tab:imdb}. While most of the models trained rather quickly, it is worth mentioning that BERT and the bidirectional LSTM both needed > 24 hours to be optimized on the validation set.


\begin{table}[h]
    \centering
    \begin{tabular}{llr}
    \hline
        \multicolumn{2}{c}{\textbf{Model}} & \textbf{Acc} \\
        \hline \hline   
        \multirow{4}{*}{TF-IDF} & Random Forest & 85.6 \\
        & SVM & 89.5 \\
        & Logistic Regression & 89.1 \\
        & MLP & 89.2 \\
        \hline 
        \multirow{4}{*}{GloVe (pretrained)} & Random Forest & \\
        & SVM & 84.1 \\
        & Logistic Regression & 85.2 \\
        & MLP & 84.1 \\
        \hline 
        \multirow{2}{*}{GloVe (jointly trained)} & MLP & 88.2 \\
        & Bidirectional LSTM & \\
        \hline 
        \multirow{4}{*}{Sentence-BERT} & Random Forest & 87.1 \\
        & SVM & 90.0 \\
        & Logistic Regression & 90.7 \\
        & MLP & 90.1 \\
        \hline
        BERT & MLP & 91.0  \\
        \hline
    \end{tabular}
\caption{Performance of used methods on the IMDb dataset. }
\label{tab:imdb}
\end{table}


\section{Index Direction Predictions}\label{sec:res_dir}

\begin{table}[H]
    \centering
    \begin{tabular}{llrrrrrr}
    \hline
        \multicolumn{2}{c}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{2}{c}{\textbf{1 year}} & \multicolumn{2}{c}{\textbf{3 year}} & \multicolumn{2}{c}{\textbf{S\&P}} \\
      & & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} \\
        \hline \hline   
        \multirow{2}{*}{Random classifier} & Most frequent & 0.56 & \textbf{68.9} & 0.44 & 59.4 & 0.37 & 53.6 \\
        & Stratified & 0.56 & 57.4 & 0.50 & 53.3 & 0.50 & 50.8 \\
        \hline 
        \multirow{4}{*}{TF-IDF} & Random Forest & 0.56 & \textbf{68.9} & 0.47 & 57.3 & 0.56 & \textbf{60.2} \\
        & SVM & 0.56 & \textbf{68.9} & 0.46 & 59.8 & 0.55 & 59.1 \\
        & Logistic Regression & 0.56 & 68.7 & 0.48 & 58.8 & \textbf{0.58} & 59.9  \\
        & MLP & 0.56 & 68.7 & 0.44 & 59.1 & 0.57 & 57.6 \\
        \hline 
        \multirow{4}{*}{GloVe (pretrain)} & Random forest & 0.42 & 67.6 & 0.40 & 58.5 & 0.55 & 58.2 \\
        & SVM & 0.41 & \textbf{68.9} & 0.37 & 59.4 & 0.35 & 53.6 \\
        & Logistic regression & 0.41 & 68.6 & 0.40 & 59.0 & 0.53 & 57.3 \\
        & MLP & 0.56 & \textbf{68.9} & 0.45 & 59.3 & 0.48 & 56.5 \\
        \hline 
        \multirow{2}{*}{GloVe (jointly trained)} & MLP & 0.41 & \textbf{68.9} & 0.37 & 59.4 & 0.47 & 55.7 \\
        & Bidirectional LSTM & 0.42 & 67.5 & 0.37 & 59.1 & 0.49 & 49.2  \\
        \hline 
        \multirow{4}{*}{Sentence-BERT} & Random forest & 0.41 & 66.6 & 0.51 & 60.4 & 0.56 & 56.8 \\
        & SVM & 0.41 & \textbf{68.9} & 0.37 & 59.4 & 0.54 & 57.0 \\
        & Logistic regression & 0.53 & 67.2 & 0.55 & 59.4 & 0.56 & 56.7  \\
        & MLP & 0.41 & \textbf{68.9} & 0.55 & 58.4 & 0.56 & 56.8 \\
        \hline
        \multirow{2}{*}{BERT} & Sigmoid & 0.41 & \textbf{68.9} & 0.38 & 59.4 & 0.48 & 50.2 \\
        & MLP & 0.41 & \textbf{68.9} & 0.37 & 59.4 & 0.38 & 54.3 \\ 
        \hline
    \end{tabular}
\caption{Performance of used methods on classifying whether the price of an index has increased from day $k-1$ to $k$ given the news titles from day $k$. The F1-score is the macro average score.}
\label{tab:rescdp}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{llrrrrrr}
    \hline
        \multicolumn{2}{c}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{2}{c}{\textbf{1 year}} & \multicolumn{2}{c}{\textbf{3 year}} & \multicolumn{2}{c}{\textbf{S\&P}} \\
      & & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} \\
        \hline \hline   
        \multirow{2}{*}{Random classifier} & Most frequent & 0.41 & 68.9 & 0.37 & 59.4 & 0.35 & 53.6 \\
        & Stratified & 0.53 & 58.5 & 0.48 & 51.5 & 0.46 & 47.4 \\
        \hline 
        \multirow{4}{*}{TF-IDF} & Random forest & 0.41 & 68.9 & 0.43 & 59.0 & 0.57 & 61.8 \\
        & SVM & 0.41 & 68.9 & 0.40 & 59.6 & 0.55 & 61.0 \\
        & Logistic regression & 0.41 & 68.9 & 0.44 & 58.4 & \textbf{0.60} & \textbf{62.7} \\
        & MLP & 0.41 & 68.9 & 0.37 & 59.4 & 0.58 & 59.4 \\
        \hline 
        \multirow{4}{*}{GloVe (pretrain)} & Random Forest & 0.56 & 67.6 & 0.48 & 58.4 & 0.52 & 53.1 \\
        & SVM & 0.56 & 68.9 & 0.44 & 59.4 & 0.37 & 53.6 \\
        & Logistic Regression & 0.56 & 68.9 & 0.50 & 59.6 & 0.56 & 58.2 \\
        & MLP & 0.56 & 68.9 & 0.44 & 59.4 & 0.55 & 55.4 \\
        \hline 
        \multirow{2}{*}{GloVe (jointly trained)} & MLP & 0.56 & 68.9 & 0.44 & 59.4 & 0.37 & 53.6 \\
        & Bidirectional LSTM & 0.56 & 68.9 & 0.45 & 58.5 & 0.48 & 48.6 \\
        \hline 
        \multirow{4}{*}{Sentence-BERT} & Random forest & 0.58 & \textbf{69.2} & 0.50 & \textbf{59.9} & 0.51 & 52.9 \\
        & SVM & 0.56 & 68.9 & 0.44 & 59.4 & 0.38 & 54.0  \\
        & Logistic regression & \textbf{0.59} & 66.6 & \textbf{0.54} & 56.3 & 0.54 & 54.3  \\
        & MLP & 0.56 & 68.9 & 0.45 & 59.8 & 0.39 & 53.1 \\
        \hline
        \multirow{2}{*}{BERT} & Sigmoid & 0.56 & 68.9 & 0.46 & 58.7 & 0.49 & 53.3 \\
        & MLP & 0.56 & 68.9 & 0.44 & 59.1 & 0.37 & 45.5 \\ 
        \hline
    \end{tabular}
\caption{Performance of used methods on classifying whether the price of an index has increased from day $k-1$ to $k$ given the news titles from day $k-1$.}
\label{tab:resndp}
\end{table}

\section{ARMA Direction Predictions}\label{sec:res_arma}


\begin{table}[H]
    \centering
    \begin{tabular}{llrrrrrr}
    \hline
        \multicolumn{2}{c}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{2}{c}{\textbf{1 year}} & \multicolumn{2}{c}{\textbf{3 year}} & \multicolumn{2}{c}{\textbf{S\&P}} \\
      & & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} \\
        \hline \hline   
        \multirow{2}{*}{Random Classifier} & Most Frequent & 0.38 & 61.1 & 0.35 & 53.8 & 0.35 & 55.0  \\
        & Stratified & 0.47 & 54.4 & 0.51 & 50.4 & 0.48 & 52.9  \\
        \hline 
        \multirow{4}{*}{TF-IDF} & Random forest & 0.46 & 62.0 & 0.50 & 53.3 & 0.46 & 55.7  \\
        & SVM & 0.46 & 62.3 & 0.49 & 56.6 & 0.45 & 56.6 \\
        & Logistic regression & 0.49 & 62.3 & 0.51 & 55.0 & 0.48 & 54.7 \\
        & MLP & 0.38 & 61.1 &   \\
        \hline 
        \multirow{4}{*}{GloVe (pretrain)} & Random Forest &
        \\
        & SVM &
        \\
        & Logistic Regression &
        \\
        & MLP &  \\
        \hline 
        \multirow{2}{*}{GloVe (jointly trained)} & MLP & \\
        & Bidirectional LSTM & \\
        \hline 
        \multirow{4}{*}{Sentence-BERT} & Random Forest & \\
        & SVM &  \\
        & Logistic Regression &   \\
        & MLP &  \\
        \hline
        \multirow{2}{*}{BERT} & Sigmoid & \\
        & MLP & \\
        \hline
    \end{tabular}
\caption{Performance of used methods on classifying whether the ARMA-prediction of an index on day $k-1$ was higher or lower than the outcome on day $k$, given the news titles from day $k$.}
\label{tab:temporary}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{llrrrrrr}
    \hline
        \multicolumn{2}{c}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{2}{c}{\textbf{1 year}} & \multicolumn{2}{c}{\textbf{3 year}} & \multicolumn{2}{c}{\textbf{S\&P}} \\
      & & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} & \textbf{F1} & \textbf{Acc} \\
        \hline \hline   
        \multirow{2}{*}{Random classifier} & Most frequent & 0.38 & 61.1 & 0.35 & 53.9 & 0.36 & 55.1 \\
        & Stratified & 0.48 & 52.8 & 0.53 & 53.1 & 0.48 & 50.3 \\
        \hline 
        \multirow{4}{*}{TF-IDF} & Random forest & 0.45 & 61.3 & 0.50 & 54.5 & 0.55 & 60.7 \\
        & SVM & 0.42 & 61.5 & 0.43 & 53.7 & 0.50 & 58.0 \\
        & Logistic regression & 0.47 & 61.0 & 0.52 & 56.7 & 0.55 & 60.2 \\
        & MLP & 0.57 & 61.8 & 0.36 & 53.6 & \\
        \hline 
        \multirow{4}{*}{GloVe (pretrain)} & Random forest & 0.50 & 60.2 & 0.51 & 52.3 & 0.50 & 57.7 \\
        & SVM & 0.38 & 61.1 & 0.35 & 53.9 & 0.36 & 55.1 \\
        & Logistic regression & 0.52 & 62.2 & 0.54 & 55.7 & 0.48 & 55.6  \\
        & MLP & 0.58 & 60.7 & 0.44 & 55.0 & 0.51 & 56.3 \\
        \hline 
        \multirow{2}{*}{GloVe (jointly trained)} & MLP & \\
        & Bidirectional LSTM & \\
        \hline 
        \multirow{4}{*}{Sentence-BERT} & Random forest & 0.56 & 63.6 & 0.55 & 56.5 & 0.59 & 61.5 \\
        & SVM & 0.38 & 61.1 & 0.53 & 57.4 & 0.51 & 59.3 \\
        & Logistic regression & 0.58 & 63.2 & 0.54 & 55.0 & 0.63 & 64.1 \\
        & MLP & 0.53 & 63.8 & 0.46 & 55.4 & 0.46 & 57.4 \\
        \hline
        \multirow{2}{*}{BERT} & Sigmoid & \\
        & MLP & \\ 
        \hline
    \end{tabular}
\caption{Performance of used methods on classifying whether the ARMA-prediction of an index on day $k-1$ was higher or lower than the outcome on day $k$, given the news titles from day $k-1$.}
\label{tab:-----}
\end{table}


